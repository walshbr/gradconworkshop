{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Brief Introduction to POS Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying the part of speech associated with a particular word is complex, even for humans. Let's talk through how a computer would go about doing this. We have to get really basic. \n",
    "\n",
    "In Python there are a few base level units of data. There are more, but to begin let's just look at two:\n",
    "\n",
    "* Integers\n",
    "* Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an integer is a whole number that you do number like things to.\n",
    "4 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_int = 4\n",
    "our_int + 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast, a string is something we can do word-like things to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FOUR'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"four\".upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fourfour'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_string = \"four\"\n",
    "\n",
    "our_string + our_string\n",
    "# what happened here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numbers can do numerical things and strings (word-type bits) can do word-type things. You can, of course, go way deeper in Python with data types, but a one more example of things you can do to strings (word-type data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f\n",
      "o\n",
      "u\n",
      "r\n"
     ]
    }
   ],
   "source": [
    "# we can print each letter out - a string is made up of its constituent pieces.\n",
    "for letter in our_string:\n",
    "    print(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is 4 equal to four?\n",
    "our_int == our_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is very literal the number four is not equal to the word four. Similarly, we can see that a word is not equal to its individual letters (we could combine those letters and get a different result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['f','o','u','r'] == 'four'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given how difficult it is for Python to parse these basic elements - how can it do more complicated things? like recognize the part of speech for a word? for a poem? We don't have to work from scratch - people build on the work of others. We can test out a basic part of speech tagger, but in order to do so we have to feed a series of words (a list) rather than a single word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'DT'),\n",
       " ('sentence', 'NN'),\n",
       " ('made', 'VBN'),\n",
       " ('of', 'IN'),\n",
       " ('words', 'NNS')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.pos_tag([\"A\", \"sentence\", \"made\", \"of\", \"words\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how did that work? Time forâ€¦\n",
    "\n",
    "## Pause for a Brief interlude on Nicholas Sparks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given these basic building blocks, let's take a poem and try to work out how we would tag it convert it into a read out of parts of speech. We'll be about as hand-wave-y as you can possibly be here, only gesturing at what the code does on a macro level. Let's run it on \"Belief\" by Josephine Miles - https://www.poetryfoundation.org/poems/46817/belief."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mother said to call her if the H-bomb exploded\n",
      "And I said I would, and it about did\n",
      "When Louis my brother robbed a service station\n",
      "And lay cursing on the oily cement in handcuffs.\n",
      "\n",
      "But by that time it was too late to tell Mother,\n",
      "She was too sick to worry the life out of her\n",
      "Over why why. Causation is sequence\n",
      "And everything is one thing after another.\n",
      "\n",
      "Besides, my other brother, Eddie, had got to be President,\n",
      "And you can't ask too much of one family.\n",
      "The chances were as good for a good future\n",
      "As bad for a bad one.\n",
      "\n",
      "Therefore it was surprising that, as we kept the newspapers from Mother,\n",
      "She died feeling responsible for a disaster unverified,\n",
      "Murmuring, in her sleep as it seemed, the ancient slogan\n",
      "Noblesse oblige.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take a poem (exists at belief.txt) and read it in\n",
    "\n",
    "filename = \"belief.txt\"\n",
    "\n",
    "with open(filename, 'r') as filein:\n",
    "    text = filein.read()\n",
    "\n",
    "# by default this is going to be the whole text as one long strings (line breaks\n",
    "# are represented by a \\n character)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('M', 'NNP'),\n",
       " ('o', 'MD'),\n",
       " ('t', 'VB'),\n",
       " ('h', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('r', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('s', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('i', 'JJ'),\n",
       " ('d', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('t', 'NN'),\n",
       " ('o', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('c', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('l', 'NN'),\n",
       " ('l', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('h', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('r', 'NN'),\n",
       " (' ', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('f', 'VBP'),\n",
       " (' ', 'JJ'),\n",
       " ('t', 'NN'),\n",
       " ('h', 'NN'),\n",
       " ('e', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('H', 'NNP'),\n",
       " ('-', ':'),\n",
       " ('b', 'NN'),\n",
       " ('o', 'NN'),\n",
       " ('m', 'NN'),\n",
       " ('b', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('e', 'NN'),\n",
       " ('x', 'NNP'),\n",
       " ('p', 'NN'),\n",
       " ('l', 'NN'),\n",
       " ('o', 'NN'),\n",
       " ('d', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('d', 'NN'),\n",
       " ('\\n', 'VBZ'),\n",
       " ('A', 'DT'),\n",
       " ('n', 'JJ'),\n",
       " ('d', 'NN'),\n",
       " (' ', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " (' ', 'VBP'),\n",
       " ('s', 'PDT'),\n",
       " ('a', 'DT'),\n",
       " ('i', 'JJ'),\n",
       " ('d', 'NN'),\n",
       " (' ', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " (' ', 'VBP'),\n",
       " ('w', 'JJ'),\n",
       " ('o', 'NN'),\n",
       " ('u', 'JJ'),\n",
       " ('l', 'NN'),\n",
       " ('d', 'NN'),\n",
       " (',', ','),\n",
       " (' ', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('n', 'JJ'),\n",
       " ('d', 'NN'),\n",
       " (' ', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('t', 'VBP'),\n",
       " (' ', 'PDT'),\n",
       " ('a', 'DT'),\n",
       " ('b', 'NN'),\n",
       " ('o', 'NN'),\n",
       " ('u', 'JJ'),\n",
       " ('t', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('d', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('d', 'VBP'),\n",
       " ('\\n', 'JJ'),\n",
       " ('W', 'NNP'),\n",
       " ('h', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('n', 'JJ'),\n",
       " (' ', 'NNP'),\n",
       " ('L', 'NNP'),\n",
       " ('o', 'IN'),\n",
       " ('u', 'JJ'),\n",
       " ('i', 'NN'),\n",
       " ('s', 'VBP'),\n",
       " (' ', 'NNP'),\n",
       " ('m', 'NN'),\n",
       " ('y', 'NN'),\n",
       " (' ', 'NN'),\n",
       " ('b', 'NN'),\n",
       " ('r', 'NN'),\n",
       " ('o', 'NN'),\n",
       " ('t', 'NN'),\n",
       " ('h', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('r', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('r', 'NN'),\n",
       " ('o', 'NN'),\n",
       " ('b', 'NN'),\n",
       " ('b', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('d', 'NN'),\n",
       " (' ', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " (' ', 'JJ'),\n",
       " ('s', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('r', 'NN'),\n",
       " ('v', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('c', 'VBP'),\n",
       " ('e', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('s', 'VBZ'),\n",
       " ('t', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('t', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('o', 'VBP'),\n",
       " ('n', 'RB'),\n",
       " ('\\n', 'VBP'),\n",
       " ('A', 'NNP'),\n",
       " ('n', 'JJ'),\n",
       " ('d', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('l', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('y', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('c', 'NN'),\n",
       " ('u', 'JJ'),\n",
       " ('r', 'NN'),\n",
       " ('s', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('n', 'VBP'),\n",
       " ('g', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('o', 'VBZ'),\n",
       " ('n', 'JJ'),\n",
       " (' ', 'NNP'),\n",
       " ('t', 'NN'),\n",
       " ('h', 'NN'),\n",
       " ('e', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('o', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('l', 'VBP'),\n",
       " ('y', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('c', 'VBZ'),\n",
       " ('e', 'FW'),\n",
       " ('m', 'FW'),\n",
       " ('e', 'FW'),\n",
       " ('n', 'FW'),\n",
       " ('t', 'IN'),\n",
       " (' ', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('n', 'VBP'),\n",
       " (' ', 'NN'),\n",
       " ('h', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('n', 'JJ'),\n",
       " ('d', 'NN'),\n",
       " ('c', 'NN'),\n",
       " ('u', 'JJ'),\n",
       " ('f', 'JJ'),\n",
       " ('f', 'NN'),\n",
       " ('s', 'NN'),\n",
       " ('.', '.'),\n",
       " ('\\n', 'CC'),\n",
       " ('\\n', 'JJ'),\n",
       " ('B', 'NNP'),\n",
       " ('u', 'NN'),\n",
       " ('t', 'NN'),\n",
       " (' ', 'NN'),\n",
       " ('b', 'NN'),\n",
       " ('y', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('t', 'NN'),\n",
       " ('h', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('t', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('t', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('m', 'VBP'),\n",
       " ('e', 'NN'),\n",
       " (' ', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('t', 'VBP'),\n",
       " (' ', 'NNP'),\n",
       " ('w', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('s', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('t', 'NN'),\n",
       " ('o', 'NN'),\n",
       " ('o', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('l', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('t', 'NN'),\n",
       " ('e', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('t', 'NN'),\n",
       " ('o', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('t', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('l', 'NN'),\n",
       " ('l', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('M', 'NNP'),\n",
       " ('o', 'MD'),\n",
       " ('t', 'VB'),\n",
       " ('h', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('r', 'NN'),\n",
       " (',', ','),\n",
       " ('\\n', 'NNP'),\n",
       " ('S', 'NNP'),\n",
       " ('h', 'NN'),\n",
       " ('e', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('w', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('s', 'JJ'),\n",
       " (' ', 'NN'),\n",
       " ('t', 'NN'),\n",
       " ('o', 'NN'),\n",
       " ('o', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('s', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('c', 'VBP'),\n",
       " ('k', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('t', 'NN'),\n",
       " ('o', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('w', 'NN'),\n",
       " ('o', 'NN'),\n",
       " ('r', 'NN'),\n",
       " ('r', 'NN'),\n",
       " ('y', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('t', 'NN'),\n",
       " ('h', 'NN'),\n",
       " ('e', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('l', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('f', 'VBP'),\n",
       " ('e', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('o', 'VBZ'),\n",
       " ('u', 'JJ'),\n",
       " ('t', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('o', 'VBZ'),\n",
       " ('f', 'JJ'),\n",
       " (' ', 'NNP'),\n",
       " ('h', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('r', 'NN'),\n",
       " ('\\n', 'NNP'),\n",
       " ('O', 'NNP'),\n",
       " ('v', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('r', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('w', 'NN'),\n",
       " ('h', 'NN'),\n",
       " ('y', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('w', 'NN'),\n",
       " ('h', 'NN'),\n",
       " ('y', 'NN'),\n",
       " ('.', '.'),\n",
       " (' ', 'VB'),\n",
       " ('C', 'NNP'),\n",
       " ('a', 'DT'),\n",
       " ('u', 'JJ'),\n",
       " ('s', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('t', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('o', 'VBP'),\n",
       " ('n', 'IN'),\n",
       " (' ', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('s', 'VBP'),\n",
       " (' ', 'JJ'),\n",
       " ('s', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('q', 'NN'),\n",
       " ('u', 'JJ'),\n",
       " ('e', 'NN'),\n",
       " ('n', 'JJ'),\n",
       " ('c', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('\\n', 'VBZ'),\n",
       " ('A', 'DT'),\n",
       " ('n', 'JJ'),\n",
       " ('d', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('e', 'NN'),\n",
       " ('v', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('r', 'NN'),\n",
       " ('y', 'NN'),\n",
       " ('t', 'NN'),\n",
       " ('h', 'NN'),\n",
       " ('i', 'JJ'),\n",
       " ('n', 'VBP'),\n",
       " ('g', 'JJ'),\n",
       " (' ', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('s', 'VBP'),\n",
       " (' ', 'JJ'),\n",
       " ('o', 'NN'),\n",
       " ('n', 'JJ'),\n",
       " ('e', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('t', 'NN'),\n",
       " ('h', 'NN'),\n",
       " ('i', 'JJ'),\n",
       " ('n', 'VBP'),\n",
       " ('g', 'JJ'),\n",
       " (' ', 'FW'),\n",
       " ('a', 'DT'),\n",
       " ('f', 'NN'),\n",
       " ('t', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('r', 'NN'),\n",
       " (' ', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('n', 'JJ'),\n",
       " ('o', 'NN'),\n",
       " ('t', 'NN'),\n",
       " ('h', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('r', 'NN'),\n",
       " ('.', '.'),\n",
       " ('\\n', 'CC'),\n",
       " ('\\n', 'JJ'),\n",
       " ('B', 'NNP'),\n",
       " ('e', 'NN'),\n",
       " ('s', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('d', 'VBP'),\n",
       " ('e', 'NN'),\n",
       " ('s', 'NN'),\n",
       " (',', ','),\n",
       " (' ', 'NNP'),\n",
       " ('m', 'NNP'),\n",
       " ('y', 'NNP'),\n",
       " (' ', 'NNP'),\n",
       " ('o', 'MD'),\n",
       " ('t', 'VB'),\n",
       " ('h', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('r', 'NN'),\n",
       " (' ', 'NN'),\n",
       " ('b', 'NN'),\n",
       " ('r', 'NN'),\n",
       " ('o', 'NN'),\n",
       " ('t', 'NN'),\n",
       " ('h', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('r', 'NN'),\n",
       " (',', ','),\n",
       " (' ', 'NNP'),\n",
       " ('E', 'NNP'),\n",
       " ('d', 'VBZ'),\n",
       " ('d', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('e', 'VBP'),\n",
       " (',', ','),\n",
       " (' ', 'VBP'),\n",
       " ('h', 'PDT'),\n",
       " ('a', 'DT'),\n",
       " ('d', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('g', 'NN'),\n",
       " ('o', 'NN'),\n",
       " ('t', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('t', 'NN'),\n",
       " ('o', 'NN'),\n",
       " (' ', 'NN'),\n",
       " ('b', 'NN'),\n",
       " ('e', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('P', 'NNP'),\n",
       " ('r', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('s', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('d', 'VBP'),\n",
       " ('e', 'NN'),\n",
       " ('n', 'JJ'),\n",
       " ('t', 'NN'),\n",
       " (',', ','),\n",
       " ('\\n', 'VB'),\n",
       " ('A', 'NNP'),\n",
       " ('n', 'JJ'),\n",
       " ('d', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('y', 'NN'),\n",
       " ('o', 'NN'),\n",
       " ('u', 'JJ'),\n",
       " (' ', 'NNP'),\n",
       " ('c', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('n', 'NN'),\n",
       " (\"'\", 'POS'),\n",
       " ('t', 'NN'),\n",
       " (' ', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('s', 'JJ'),\n",
       " ('k', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('t', 'NN'),\n",
       " ('o', 'NN'),\n",
       " ('o', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('m', 'NN'),\n",
       " ('u', 'JJ'),\n",
       " ('c', 'NN'),\n",
       " ('h', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('o', 'VBZ'),\n",
       " ('f', 'JJ'),\n",
       " (' ', 'NNP'),\n",
       " ('o', 'NN'),\n",
       " ('n', 'NN'),\n",
       " ('e', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('f', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('m', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('l', 'VBP'),\n",
       " ('y', 'NN'),\n",
       " ('.', '.'),\n",
       " ('\\n', 'CC'),\n",
       " ('T', 'NNP'),\n",
       " ('h', 'VBP'),\n",
       " ('e', 'JJ'),\n",
       " (' ', 'NNP'),\n",
       " ('c', 'NN'),\n",
       " ('h', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('n', 'JJ'),\n",
       " ('c', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('s', 'JJ'),\n",
       " (' ', 'NNP'),\n",
       " ('w', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('r', 'NN'),\n",
       " ('e', 'NN'),\n",
       " (' ', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('s', 'JJ'),\n",
       " (' ', 'NN'),\n",
       " ('g', 'NN'),\n",
       " ('o', 'NN'),\n",
       " ('o', 'NN'),\n",
       " ('d', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('f', 'NN'),\n",
       " ('o', 'NN'),\n",
       " ('r', 'NN'),\n",
       " (' ', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " (' ', 'JJ'),\n",
       " ('g', 'NN'),\n",
       " ('o', 'NN'),\n",
       " ('o', 'NN'),\n",
       " ('d', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('f', 'NN'),\n",
       " ('u', 'JJ'),\n",
       " ('t', 'NN'),\n",
       " ('u', 'JJ'),\n",
       " ('r', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('\\n', 'VBZ'),\n",
       " ('A', 'DT'),\n",
       " ('s', 'NN'),\n",
       " (' ', 'NN'),\n",
       " ('b', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('d', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('f', 'NN'),\n",
       " ('o', 'NN'),\n",
       " ('r', 'NN'),\n",
       " (' ', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " (' ', 'NN'),\n",
       " ('b', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('d', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('o', 'VBZ'),\n",
       " ('n', 'JJ'),\n",
       " ('e', 'NN'),\n",
       " ('.', '.'),\n",
       " ('\\n', 'CC'),\n",
       " ('\\n', 'JJ'),\n",
       " ('T', 'NNP'),\n",
       " ('h', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('r', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('f', 'NN'),\n",
       " ('o', 'NN'),\n",
       " ('r', 'NN'),\n",
       " ('e', 'NN'),\n",
       " (' ', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('t', 'VBP'),\n",
       " (' ', 'NNP'),\n",
       " ('w', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('s', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('s', 'NN'),\n",
       " ('u', 'JJ'),\n",
       " ('r', 'NN'),\n",
       " ('p', 'NN'),\n",
       " ('r', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('s', 'VBP'),\n",
       " ('i', 'NN'),\n",
       " ('n', 'VBP'),\n",
       " ('g', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('t', 'NN'),\n",
       " ('h', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('t', 'NN'),\n",
       " (',', ','),\n",
       " (' ', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('s', 'JJ'),\n",
       " (' ', 'NN'),\n",
       " ('w', 'NN'),\n",
       " ('e', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('k', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('p', 'NN'),\n",
       " ('t', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('t', 'NN'),\n",
       " ('h', 'NN'),\n",
       " ('e', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('n', 'CC'),\n",
       " ('e', 'JJ'),\n",
       " ('w', 'NN'),\n",
       " ('s', 'NN'),\n",
       " ('p', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('p', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('r', 'NN'),\n",
       " ('s', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('f', 'NN'),\n",
       " ('r', 'NN'),\n",
       " ('o', 'IN'),\n",
       " ('m', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('M', 'NNP'),\n",
       " ('o', 'MD'),\n",
       " ('t', 'VB'),\n",
       " ('h', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('r', 'NN'),\n",
       " (',', ','),\n",
       " ('\\n', 'NNP'),\n",
       " ('S', 'NNP'),\n",
       " ('h', 'NN'),\n",
       " ('e', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('d', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('e', 'VBP'),\n",
       " ('d', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('f', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('e', 'IN'),\n",
       " ('l', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('n', 'VBP'),\n",
       " ('g', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('r', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('s', 'NN'),\n",
       " ('p', 'NN'),\n",
       " ('o', 'NN'),\n",
       " ('n', 'IN'),\n",
       " ('s', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('b', 'VBP'),\n",
       " ('l', 'NN'),\n",
       " ('e', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('f', 'NN'),\n",
       " ('o', 'NN'),\n",
       " ('r', 'NN'),\n",
       " (' ', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " (' ', 'JJ'),\n",
       " ('d', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('s', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('s', 'NN'),\n",
       " ('t', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('r', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('u', 'JJ'),\n",
       " ('n', 'RB'),\n",
       " ('v', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('r', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('f', 'VBP'),\n",
       " ('i', 'NN'),\n",
       " ('e', 'VBP'),\n",
       " ('d', 'NN'),\n",
       " (',', ','),\n",
       " ('\\n', 'NNP'),\n",
       " ('M', 'NNP'),\n",
       " ('u', 'JJ'),\n",
       " ('r', 'NN'),\n",
       " ('m', 'NN'),\n",
       " ('u', 'JJ'),\n",
       " ('r', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('n', 'VBP'),\n",
       " ('g', 'NN'),\n",
       " (',', ','),\n",
       " (' ', 'VBP'),\n",
       " ('i', 'JJ'),\n",
       " ('n', 'VBP'),\n",
       " (' ', 'JJ'),\n",
       " ('h', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('r', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('s', 'NN'),\n",
       " ('l', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('p', 'NN'),\n",
       " (' ', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('s', 'JJ'),\n",
       " (' ', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('t', 'VBP'),\n",
       " (' ', 'JJ'),\n",
       " ('s', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('e', 'VBP'),\n",
       " ('m', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('d', 'NN'),\n",
       " (',', ','),\n",
       " (' ', 'NNP'),\n",
       " ('t', 'NN'),\n",
       " ('h', 'NN'),\n",
       " ('e', 'NN'),\n",
       " (' ', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('n', 'JJ'),\n",
       " ('c', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('e', 'VBP'),\n",
       " ('n', 'JJ'),\n",
       " ('t', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('s', 'NN'),\n",
       " ('l', 'NN'),\n",
       " ('o', 'NN'),\n",
       " ('g', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('n', 'JJ'),\n",
       " ('\\n', 'NN'),\n",
       " ('N', 'NNP'),\n",
       " ('o', 'NN'),\n",
       " ('b', 'NN'),\n",
       " ('l', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('s', 'NN'),\n",
       " ('s', 'NN'),\n",
       " ('e', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('o', 'NN'),\n",
       " ('b', 'NN'),\n",
       " ('l', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('g', 'VBP'),\n",
       " ('e', 'NN'),\n",
       " ('.', '.'),\n",
       " ('\\n', 'NN')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tag the poem!\n",
    "\n",
    "import nltk\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops that didn't work. Remember that the POS tagger we're using requires a list of words, and it read our file in as one long string. By default a string is divided into characters - it doesn't know what a \"word\" is. So we have to break that poem into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mother',\n",
       " 'said',\n",
       " 'to',\n",
       " 'call',\n",
       " 'her',\n",
       " 'if',\n",
       " 'the',\n",
       " 'H-bomb',\n",
       " 'exploded',\n",
       " 'And',\n",
       " 'I',\n",
       " 'said',\n",
       " 'I',\n",
       " 'would',\n",
       " ',',\n",
       " 'and',\n",
       " 'it',\n",
       " 'about',\n",
       " 'did',\n",
       " 'When',\n",
       " 'Louis',\n",
       " 'my',\n",
       " 'brother',\n",
       " 'robbed',\n",
       " 'a',\n",
       " 'service',\n",
       " 'station',\n",
       " 'And',\n",
       " 'lay',\n",
       " 'cursing',\n",
       " 'on',\n",
       " 'the',\n",
       " 'oily',\n",
       " 'cement',\n",
       " 'in',\n",
       " 'handcuffs',\n",
       " '.',\n",
       " 'But',\n",
       " 'by',\n",
       " 'that',\n",
       " 'time',\n",
       " 'it',\n",
       " 'was',\n",
       " 'too',\n",
       " 'late',\n",
       " 'to',\n",
       " 'tell',\n",
       " 'Mother',\n",
       " ',',\n",
       " 'She',\n",
       " 'was',\n",
       " 'too',\n",
       " 'sick',\n",
       " 'to',\n",
       " 'worry',\n",
       " 'the',\n",
       " 'life',\n",
       " 'out',\n",
       " 'of',\n",
       " 'her',\n",
       " 'Over',\n",
       " 'why',\n",
       " 'why',\n",
       " '.',\n",
       " 'Causation',\n",
       " 'is',\n",
       " 'sequence',\n",
       " 'And',\n",
       " 'everything',\n",
       " 'is',\n",
       " 'one',\n",
       " 'thing',\n",
       " 'after',\n",
       " 'another',\n",
       " '.',\n",
       " 'Besides',\n",
       " ',',\n",
       " 'my',\n",
       " 'other',\n",
       " 'brother',\n",
       " ',',\n",
       " 'Eddie',\n",
       " ',',\n",
       " 'had',\n",
       " 'got',\n",
       " 'to',\n",
       " 'be',\n",
       " 'President',\n",
       " ',',\n",
       " 'And',\n",
       " 'you',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'ask',\n",
       " 'too',\n",
       " 'much',\n",
       " 'of',\n",
       " 'one',\n",
       " 'family',\n",
       " '.',\n",
       " 'The',\n",
       " 'chances',\n",
       " 'were',\n",
       " 'as',\n",
       " 'good',\n",
       " 'for',\n",
       " 'a',\n",
       " 'good',\n",
       " 'future',\n",
       " 'As',\n",
       " 'bad',\n",
       " 'for',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'one',\n",
       " '.',\n",
       " 'Therefore',\n",
       " 'it',\n",
       " 'was',\n",
       " 'surprising',\n",
       " 'that',\n",
       " ',',\n",
       " 'as',\n",
       " 'we',\n",
       " 'kept',\n",
       " 'the',\n",
       " 'newspapers',\n",
       " 'from',\n",
       " 'Mother',\n",
       " ',',\n",
       " 'She',\n",
       " 'died',\n",
       " 'feeling',\n",
       " 'responsible',\n",
       " 'for',\n",
       " 'a',\n",
       " 'disaster',\n",
       " 'unverified',\n",
       " ',',\n",
       " 'Murmuring',\n",
       " ',',\n",
       " 'in',\n",
       " 'her',\n",
       " 'sleep',\n",
       " 'as',\n",
       " 'it',\n",
       " 'seemed',\n",
       " ',',\n",
       " 'the',\n",
       " 'ancient',\n",
       " 'slogan',\n",
       " 'Noblesse',\n",
       " 'oblige',\n",
       " '.']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# break a text into a series of words\n",
    "\n",
    "words = nltk.word_tokenize(text)\n",
    "    \n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NNP VBD TO VB PRP IN DT NNP VBD CC PRP VBD PRP MD , CC PRP RB VBD WRB NNP PRP$ NN VBD DT NN NN CC VBD VBG IN DT JJ NN IN NNS . CC IN DT NN PRP VBD RB JJ TO VB NNP , PRP VBD RB JJ TO VB DT NN IN IN PRP$ NNP WRB WRB . NN VBZ JJ CC NN VBZ CD NN IN DT . IN , PRP$ JJ NN , NNP , VBD VBN TO VB NNP , CC PRP MD RB VB RB JJ IN CD NN . DT NNS VBD RB JJ IN DT JJ NN IN JJ IN DT JJ CD . VB PRP VBD VBG RB , IN PRP VBD DT NNS IN NNP , PRP VBD VBG JJ IN DT NN JJ , NNP , IN PRP$ NN IN PRP VBD , DT NN JJ NNP NN .'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_pairs = nltk.pos_tag(words)\n",
    "\n",
    "just_tags = []\n",
    "for tag_pair in tag_pairs:\n",
    "    just_tags.append(tag_pair[1])\n",
    "    \n",
    "' '.join(just_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But that is a little unhelpful, because it takes the tags and combines them one long line of text. This is poetry, and we want to respect the lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Mother', 'said', 'to', 'call', 'her', 'if', 'the', 'H-bomb', 'exploded'],\n",
       " ['And', 'I', 'said', 'I', 'would', ',', 'and', 'it', 'about', 'did'],\n",
       " ['When', 'Louis', 'my', 'brother', 'robbed', 'a', 'service', 'station'],\n",
       " ['And',\n",
       "  'lay',\n",
       "  'cursing',\n",
       "  'on',\n",
       "  'the',\n",
       "  'oily',\n",
       "  'cement',\n",
       "  'in',\n",
       "  'handcuffs',\n",
       "  '.'],\n",
       " [],\n",
       " ['But',\n",
       "  'by',\n",
       "  'that',\n",
       "  'time',\n",
       "  'it',\n",
       "  'was',\n",
       "  'too',\n",
       "  'late',\n",
       "  'to',\n",
       "  'tell',\n",
       "  'Mother',\n",
       "  ','],\n",
       " ['She',\n",
       "  'was',\n",
       "  'too',\n",
       "  'sick',\n",
       "  'to',\n",
       "  'worry',\n",
       "  'the',\n",
       "  'life',\n",
       "  'out',\n",
       "  'of',\n",
       "  'her'],\n",
       " ['Over', 'why', 'why', '.', 'Causation', 'is', 'sequence'],\n",
       " ['And', 'everything', 'is', 'one', 'thing', 'after', 'another', '.'],\n",
       " [],\n",
       " ['Besides',\n",
       "  ',',\n",
       "  'my',\n",
       "  'other',\n",
       "  'brother',\n",
       "  ',',\n",
       "  'Eddie',\n",
       "  ',',\n",
       "  'had',\n",
       "  'got',\n",
       "  'to',\n",
       "  'be',\n",
       "  'President',\n",
       "  ','],\n",
       " ['And', 'you', 'ca', \"n't\", 'ask', 'too', 'much', 'of', 'one', 'family', '.'],\n",
       " ['The', 'chances', 'were', 'as', 'good', 'for', 'a', 'good', 'future'],\n",
       " ['As', 'bad', 'for', 'a', 'bad', 'one', '.'],\n",
       " [],\n",
       " ['Therefore',\n",
       "  'it',\n",
       "  'was',\n",
       "  'surprising',\n",
       "  'that',\n",
       "  ',',\n",
       "  'as',\n",
       "  'we',\n",
       "  'kept',\n",
       "  'the',\n",
       "  'newspapers',\n",
       "  'from',\n",
       "  'Mother',\n",
       "  ','],\n",
       " ['She',\n",
       "  'died',\n",
       "  'feeling',\n",
       "  'responsible',\n",
       "  'for',\n",
       "  'a',\n",
       "  'disaster',\n",
       "  'unverified',\n",
       "  ','],\n",
       " ['Murmuring',\n",
       "  ',',\n",
       "  'in',\n",
       "  'her',\n",
       "  'sleep',\n",
       "  'as',\n",
       "  'it',\n",
       "  'seemed',\n",
       "  ',',\n",
       "  'the',\n",
       "  'ancient',\n",
       "  'slogan'],\n",
       " ['Noblesse', 'oblige', '.']]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(filename, 'r') as filein:\n",
    "    lines = filein.readlines()\n",
    "\n",
    "tokenized_lines = []\n",
    "for line in lines:\n",
    "    words = nltk.word_tokenize(line)\n",
    "    tokenized_lines.append(words)\n",
    "\n",
    "tokenized_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NNP', 'VBD', 'TO', 'VB', 'PRP', 'IN', 'DT', 'NNP', 'VBD'],\n",
       " ['CC', 'PRP', 'VBD', 'PRP', 'MD', ',', 'CC', 'PRP', 'RB', 'VBD'],\n",
       " ['WRB', 'NNP', 'PRP$', 'NN', 'VBD', 'DT', 'NN', 'NN'],\n",
       " ['CC', 'VB', 'VBG', 'IN', 'DT', 'JJ', 'NN', 'IN', 'NNS', '.'],\n",
       " [],\n",
       " ['CC', 'IN', 'DT', 'NN', 'PRP', 'VBD', 'RB', 'JJ', 'TO', 'VB', 'NNP', ','],\n",
       " ['PRP', 'VBD', 'RB', 'JJ', 'TO', 'VB', 'DT', 'NN', 'IN', 'IN', 'PRP$'],\n",
       " ['IN', 'WRB', 'WRB', '.', 'NN', 'VBZ', 'NN'],\n",
       " ['CC', 'NN', 'VBZ', 'CD', 'NN', 'IN', 'DT', '.'],\n",
       " [],\n",
       " ['IN',\n",
       "  ',',\n",
       "  'PRP$',\n",
       "  'JJ',\n",
       "  'NN',\n",
       "  ',',\n",
       "  'NNP',\n",
       "  ',',\n",
       "  'VBD',\n",
       "  'VBN',\n",
       "  'TO',\n",
       "  'VB',\n",
       "  'NNP',\n",
       "  ','],\n",
       " ['CC', 'PRP', 'MD', 'RB', 'VB', 'RB', 'JJ', 'IN', 'CD', 'NN', '.'],\n",
       " ['DT', 'NNS', 'VBD', 'RB', 'JJ', 'IN', 'DT', 'JJ', 'NN'],\n",
       " ['IN', 'JJ', 'IN', 'DT', 'JJ', 'CD', '.'],\n",
       " [],\n",
       " ['IN',\n",
       "  'PRP',\n",
       "  'VBD',\n",
       "  'VBG',\n",
       "  'RB',\n",
       "  ',',\n",
       "  'IN',\n",
       "  'PRP',\n",
       "  'VBD',\n",
       "  'DT',\n",
       "  'NNS',\n",
       "  'IN',\n",
       "  'NNP',\n",
       "  ','],\n",
       " ['PRP', 'VBD', 'VBG', 'JJ', 'IN', 'DT', 'NN', 'JJ', ','],\n",
       " ['VBG', ',', 'IN', 'PRP$', 'NN', 'IN', 'PRP', 'VBD', ',', 'DT', 'NN', 'NN'],\n",
       " ['NNP', 'NN', '.']]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now that we have the lines as a series of words (or tokens) - let's go through and tag them\n",
    "\n",
    "tagged_lines = []\n",
    "for line in tokenized_lines:\n",
    "    tagged_lines.append(nltk.pos_tag(line))\n",
    "\n",
    "just_tags_for_lines = []\n",
    "\n",
    "for line in tagged_lines:\n",
    "    this_line = []\n",
    "    for tag_pair in line:\n",
    "        this_line.append(tag_pair[1])\n",
    "    just_tags_for_lines.append(this_line)\n",
    "\n",
    "just_tags_for_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP VBD TO VB PRP IN DT NNP VBD\n",
      "CC PRP VBD PRP MD , CC PRP RB VBD\n",
      "WRB NNP PRP$ NN VBD DT NN NN\n",
      "CC VB VBG IN DT JJ NN IN NNS .\n",
      "\n",
      "CC IN DT NN PRP VBD RB JJ TO VB NNP ,\n",
      "PRP VBD RB JJ TO VB DT NN IN IN PRP$\n",
      "IN WRB WRB . NN VBZ NN\n",
      "CC NN VBZ CD NN IN DT .\n",
      "\n",
      "IN , PRP$ JJ NN , NNP , VBD VBN TO VB NNP ,\n",
      "CC PRP MD RB VB RB JJ IN CD NN .\n",
      "DT NNS VBD RB JJ IN DT JJ NN\n",
      "IN JJ IN DT JJ CD .\n",
      "\n",
      "IN PRP VBD VBG RB , IN PRP VBD DT NNS IN NNP ,\n",
      "PRP VBD VBG JJ IN DT NN JJ ,\n",
      "VBG , IN PRP$ NN IN PRP VBD , DT NN NN\n",
      "NNP NN .\n"
     ]
    }
   ],
   "source": [
    "# but that is kind of gross to read, so let's put things back together as a poem,\n",
    "# without the brackets, commas, etc. that python requires to run\n",
    "\n",
    "transformed_poem = []\n",
    "for line in just_tags_for_lines:\n",
    "    transformed_poem.append(' '.join(line))\n",
    "    \n",
    "    \n",
    "for line in transformed_poem:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP VBD TO VB PRP IN DT NNP VBD\n",
      "CC PRP VBD PRP MD , CC PRP RB VBD\n",
      "WRB NNP PRP$ NN VBD DT NN NN\n",
      "CC VB VBG IN DT JJ NN IN NNS .\n",
      "\n",
      "CC IN DT NN PRP VBD RB JJ TO VB NNP ,\n",
      "PRP VBD RB JJ TO VB DT NN IN IN PRP$\n",
      "IN WRB WRB . NN VBZ NN\n",
      "CC NN VBZ CD NN IN DT .\n",
      "\n",
      "IN , PRP$ JJ NN , NNP , VBD VBN TO VB NNP ,\n",
      "CC PRP MD RB VB RB JJ IN CD NN .\n",
      "DT NNS VBD RB JJ IN DT JJ NN\n",
      "IN JJ IN DT JJ CD .\n",
      "\n",
      "IN PRP VBD VBG RB , IN PRP VBD DT NNS IN NNP ,\n",
      "PRP VBD VBG JJ IN DT NN JJ ,\n",
      "VBG , IN PRP$ NN IN PRP VBD , DT NN NN\n",
      "NNP NN .\n"
     ]
    }
   ],
   "source": [
    "#  let's make that a function for ease of use:\n",
    "def nltk_pos_transform(filename):\n",
    "    \"\"\"Given a filename, take a poem and transform it into its POS tags\"\"\"\n",
    "    with open(filename, 'r') as filein:\n",
    "        lines = filein.readlines()\n",
    "\n",
    "    tokenized_lines = []\n",
    "    for line in lines:\n",
    "        words = nltk.word_tokenize(line)\n",
    "        tokenized_lines.append(words)\n",
    "\n",
    "    tagged_lines = []\n",
    "    for line in tokenized_lines:\n",
    "        tagged_lines.append(nltk.pos_tag(line))\n",
    "\n",
    "    just_tags_for_lines = []\n",
    "\n",
    "    for line in tagged_lines:\n",
    "        this_line = []\n",
    "        for tag_pair in line:\n",
    "            this_line.append(tag_pair[1])\n",
    "        just_tags_for_lines.append(this_line)\n",
    "\n",
    "    # reconstituting them now\n",
    "    transformed_poem = []\n",
    "    for line in just_tags_for_lines:\n",
    "        transformed_poem.append(' '.join(line))\n",
    "\n",
    "\n",
    "    for line in transformed_poem:\n",
    "        print(line)\n",
    "\n",
    "nltk_pos_transform('belief.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN VBD TO VB PRP IN DT NN HYPH NN VBD _SP\n",
      "CC PRP VBD PRP MD , CC PRP IN VBD _SP\n",
      "WRB NNP PRP$ NN VBD DT NN NN _SP\n",
      "CC VB VBG IN DT JJ NN IN NNS . _SP\n",
      "_SP\n",
      "CC IN DT NN PRP VBD RB JJ TO VB NNP , _SP\n",
      "PRP VBD RB JJ TO VB DT NN IN IN PRP _SP\n",
      "IN WRB WRB . NN VBZ NN _SP\n",
      "CC NN VBZ CD NN IN DT . _SP\n",
      "_SP\n",
      "RB , PRP$ JJ NN , NNP , VBD VBN TO VB NNP , _SP\n",
      "CC PRP MD RB VB RB JJ IN CD NN . _SP\n",
      "DT NNS VBD RB JJ IN DT JJ NN _SP\n",
      "RB JJ IN DT JJ NN . _SP\n",
      "_SP\n",
      "RB PRP VBD JJ IN , IN PRP VBD DT NNS IN NNP , _SP\n",
      "PRP VBD VBG JJ IN DT NN JJ , _SP\n",
      "VBG , IN PRP$ NN IN PRP VBD , DT JJ NN _SP\n",
      "NNP NN . _SP\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "# let's do the same thing with spacy\n",
    "\n",
    "def spacy_pos_transform(filename):\n",
    "    \"\"\"Given a filename, take a poem and transform it into its POS tags\"\"\"\n",
    "    nlp = en_core_web_sm.load()\n",
    "    with open(filename, 'r') as filein:\n",
    "        lines = filein.readlines()\n",
    "\n",
    "    spacy_lines = []\n",
    "    for line in lines:\n",
    "        this_line = []\n",
    "        doc = nlp(line)\n",
    "        for token in doc:\n",
    "            this_line.append(token.tag_) \n",
    "        spacy_lines.append(this_line)\n",
    "    # reconstituting them now\n",
    "    transformed_poem = []\n",
    "    for line in spacy_lines:\n",
    "        transformed_poem.append(' '.join(line))\n",
    "\n",
    "\n",
    "    for line in transformed_poem:\n",
    "        print(line)\n",
    "\n",
    "spacy_pos_transform('belief.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the two against each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK transform results:\n",
      "NNP VBD TO VB PRP IN DT NNP VBD\n",
      "CC PRP VBD PRP MD , CC PRP RB VBD\n",
      "WRB NNP PRP$ NN VBD DT NN NN\n",
      "CC VB VBG IN DT JJ NN IN NNS .\n",
      "\n",
      "CC IN DT NN PRP VBD RB JJ TO VB NNP ,\n",
      "PRP VBD RB JJ TO VB DT NN IN IN PRP$\n",
      "IN WRB WRB . NN VBZ NN\n",
      "CC NN VBZ CD NN IN DT .\n",
      "\n",
      "IN , PRP$ JJ NN , NNP , VBD VBN TO VB NNP ,\n",
      "CC PRP MD RB VB RB JJ IN CD NN .\n",
      "DT NNS VBD RB JJ IN DT JJ NN\n",
      "IN JJ IN DT JJ CD .\n",
      "\n",
      "IN PRP VBD VBG RB , IN PRP VBD DT NNS IN NNP ,\n",
      "PRP VBD VBG JJ IN DT NN JJ ,\n",
      "VBG , IN PRP$ NN IN PRP VBD , DT NN NN\n",
      "NNP NN .\n",
      "=========\n",
      "Spacy transform results:\n",
      "NN VBD TO VB PRP IN DT NN HYPH NN VBD _SP\n",
      "CC PRP VBD PRP MD , CC PRP IN VBD _SP\n",
      "WRB NNP PRP$ NN VBD DT NN NN _SP\n",
      "CC VB VBG IN DT JJ NN IN NNS . _SP\n",
      "_SP\n",
      "CC IN DT NN PRP VBD RB JJ TO VB NNP , _SP\n",
      "PRP VBD RB JJ TO VB DT NN IN IN PRP _SP\n",
      "IN WRB WRB . NN VBZ NN _SP\n",
      "CC NN VBZ CD NN IN DT . _SP\n",
      "_SP\n",
      "RB , PRP$ JJ NN , NNP , VBD VBN TO VB NNP , _SP\n",
      "CC PRP MD RB VB RB JJ IN CD NN . _SP\n",
      "DT NNS VBD RB JJ IN DT JJ NN _SP\n",
      "RB JJ IN DT JJ NN . _SP\n",
      "_SP\n",
      "RB PRP VBD JJ IN , IN PRP VBD DT NNS IN NNP , _SP\n",
      "PRP VBD VBG JJ IN DT NN JJ , _SP\n",
      "VBG , IN PRP$ NN IN PRP VBD , DT JJ NN _SP\n",
      "NNP NN . _SP\n"
     ]
    }
   ],
   "source": [
    "print('NLTK transform results:')\n",
    "nltk_pos_transform('belief.txt')\n",
    "print('=========')\n",
    "print('Spacy transform results:')\n",
    "spacy_pos_transform('belief.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can be difficult to compare. Let's make a function that compares the two outputs and gives a 1 if they are the same or a 0 if they are different. And since you might want to upload your text, let's change things slightly. Rather than use a poem, the following code block will just take a long pasted string. So you could paste your own poem from on the web if you'd like!  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK transform results:\n",
      "\n",
      "NNP VBD TO VB PRP IN DT NNP VBD\n",
      "CC PRP VBD PRP MD , CC PRP RB VBD\n",
      "WRB NNP PRP$ NN VBD DT NN NN\n",
      "CC VB VBG IN DT JJ NN IN NNS .\n",
      "\n",
      "CC IN DT NN PRP VBD RB JJ TO VB NNP ,\n",
      "PRP VBD RB JJ TO VB DT NN IN IN PRP$\n",
      "IN WRB WRB . NN VBZ NN\n",
      "CC NN VBZ CD NN IN DT .\n",
      "\n",
      "IN , PRP$ JJ NN , NNP , VBD VBN TO VB NNP ,\n",
      "CC PRP MD RB VB RB JJ IN CD NN .\n",
      "DT NNS VBD RB JJ IN DT JJ NN\n",
      "IN JJ IN DT JJ CD .\n",
      "\n",
      "IN PRP VBD VBG RB , IN PRP VBD DT NNS IN NNP ,\n",
      "PRP VBD VBG JJ IN DT NN JJ ,\n",
      "VBG , IN PRP$ NN IN PRP VBD , DT NN NN\n",
      "NNP NN .\n",
      "\n",
      "=========\n",
      "Spacy transform results:\n",
      "\n",
      "NN VBD TO VB PRP IN DT NN HYPH NN VBD\n",
      "CC PRP VBD PRP MD , CC PRP IN VBD\n",
      "WRB NNP PRP$ NN VBD DT NN NN\n",
      "CC VB VBG IN DT JJ NN IN NNS .\n",
      "\n",
      "CC IN DT NN PRP VBD RB JJ TO VB NNP ,\n",
      "PRP VBD RB JJ TO VB DT NN IN IN PRP\n",
      "IN WRB WRB . NN VBZ NN\n",
      "CC NN VBZ CD NN IN DT .\n",
      "\n",
      "RB , PRP$ JJ NN , NNP , VBD VBN TO VB NNP ,\n",
      "CC PRP MD RB VB RB JJ IN CD NN .\n",
      "DT NNS VBD RB JJ IN DT JJ NN\n",
      "RB JJ IN DT JJ NN .\n",
      "\n",
      "RB PRP VBD JJ IN , IN PRP VBD DT NNS IN NNP ,\n",
      "PRP VBD VBG JJ IN DT NN JJ ,\n",
      "VBG , IN PRP$ NN IN PRP VBD , DT JJ NN\n",
      "NNP NN .\n",
      "\n",
      "Comparison - zero is where they do not tag the same\n",
      "\n",
      "0 1 1 1 1 1 1 0 0\n",
      "1 1 1 1 1 1 1 1 0\n",
      "1 1 1 1 1 1 1 1\n",
      "1 1 1 1 1 1 1 1 1\n",
      "\n",
      "1 1 1 1 1 1 1 1 1 1 1\n",
      "1 1 1 1 1 1 1 1 1 1\n",
      "1 1 1 1 1 1\n",
      "1 1 1 1 1 1 1\n",
      "\n",
      "0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "1 1 1 1 1 1 1 1 1 1\n",
      "1 1 1 1 1 1 1 1\n",
      "0 1 1 1 1 0\n",
      "\n",
      "0 1 1 0 0 1 1 1 1 1 1 1 1\n",
      "1 1 1 1 1 1 1 1\n",
      "1 1 1 1 1 1 1 1 1 1 1 0\n",
      "1 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "our_text = \"\"\"\n",
    "Mother said to call her if the H-bomb exploded\n",
    "And I said I would, and it about did\n",
    "When Louis my brother robbed a service station\n",
    "And lay cursing on the oily cement in handcuffs.\n",
    "\n",
    "But by that time it was too late to tell Mother,\n",
    "She was too sick to worry the life out of her\n",
    "Over why why. Causation is sequence\n",
    "And everything is one thing after another.\n",
    "\n",
    "Besides, my other brother, Eddie, had got to be President,\n",
    "And you can't ask too much of one family.\n",
    "The chances were as good for a good future\n",
    "As bad for a bad one.\n",
    "\n",
    "Therefore it was surprising that, as we kept the newspapers from Mother,\n",
    "She died feeling responsible for a disaster unverified,\n",
    "Murmuring, in her sleep as it seemed, the ancient slogan\n",
    "Noblesse oblige.\n",
    "\"\"\"\n",
    "\n",
    "def spacy_pos_transform(text):\n",
    "    \"\"\"Given a string pasted in, take a poem and transform it into its POS tags\"\"\"\n",
    "    nlp = en_core_web_sm.load()\n",
    "    lines = text.split('\\n')\n",
    "    spacy_lines = []\n",
    "    for line in lines:\n",
    "        this_line = []\n",
    "        doc = nlp(line)\n",
    "        for token in doc:\n",
    "            this_line.append(token.tag_) \n",
    "        spacy_lines.append(this_line)\n",
    "    # reconstituting them now\n",
    "    transformed_poem = []\n",
    "    for line in spacy_lines:\n",
    "        transformed_poem.append(' '.join(line))\n",
    "\n",
    "    return transformed_poem\n",
    "\n",
    "def nltk_pos_transform(text):\n",
    "    \"\"\"Given a string pasted in, take a poem and transform it into its POS tags\"\"\"\n",
    "    lines = text.split('\\n')\n",
    "    tokenized_lines = []\n",
    "    for line in lines:\n",
    "        words = nltk.word_tokenize(line)\n",
    "        tokenized_lines.append(words)\n",
    "    tagged_lines = []\n",
    "    for line in tokenized_lines:\n",
    "        tagged_lines.append(nltk.pos_tag(line))\n",
    "    just_tags_for_lines = []\n",
    "\n",
    "    for line in tagged_lines:\n",
    "        this_line = []\n",
    "        for tag_pair in line:\n",
    "            this_line.append(tag_pair[1])\n",
    "        just_tags_for_lines.append(this_line)\n",
    "    # reconstituting them now\n",
    "    transformed_poem = []\n",
    "    for line in just_tags_for_lines:\n",
    "        transformed_poem.append(' '.join(line))\n",
    "    return transformed_poem\n",
    "\n",
    "def binary_poem(spacy_text, nltk_text):\n",
    "    binary_poem = []\n",
    "    line_counter = 0\n",
    "    for line in spacy_text:\n",
    "        this_line = []\n",
    "        spacy_line = nltk.word_tokenize(line)\n",
    "        nltk_line = nltk.word_tokenize(nltk_text[line_counter])\n",
    "        for num, word in enumerate(spacy_line[:-1], start=0):\n",
    "            try:\n",
    "                if word == nltk_line[num]:\n",
    "                    this_line.append(1)\n",
    "                else:\n",
    "                    this_line.append(0)\n",
    "            except:\n",
    "                pass\n",
    "        binary_poem.append(this_line)\n",
    "        line_counter += 1\n",
    "    return binary_poem\n",
    "\n",
    "spacy_text = spacy_pos_transform(our_text)\n",
    "nltk_text = nltk_pos_transform(our_text)\n",
    "binary_poem = binary_poem(spacy_text, nltk_text)\n",
    "\n",
    "print('NLTK transform results:')\n",
    "for line in nltk_text:\n",
    "    print(line)\n",
    "print('=========')\n",
    "print('Spacy transform results:')\n",
    "for line in spacy_text:\n",
    "    print(line)\n",
    "print('Comparison - zero is where they do not tag the same')\n",
    "for line in binary_poem:\n",
    "    line = [str(item) for item in line]\n",
    "    print(' '.join(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're interested in digging deeper into the systems each of these tagging systems uses for part of speech:\n",
    "\n",
    "* NLTK is trained on a wall street journal corpus: https://stackoverflow.com/questions/32016545/how-does-nltk-pos-tag-work/41384824#:~:text=This%20basically%20means%20that%20it,not%20the%20guess%20was%20correct. It actually uses weighted averages.\n",
    "* More information on POS tagging systems - https://universaldependencies.org/docs/u/pos/\n",
    "\n",
    "* Spacy uses - OntoNotes Release 5.0 is the final release of the OntoNotes project, a collaborative effort between BBN Technologies, the University of Colorado, the University of Pennsylvania and the University of Southern Californias Information Sciences Institute. The goal of the project was to annotate a large corpus comprising various genres of text (news, conversational telephone speech, weblogs, usenet newsgroups, broadcast, talk shows) in three languages (English, Chinese, and Arabic) with structural information (syntax and predicate argument structure) and shallow semantics (word sense linked to an ontology and coreference).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion Questions:\n",
    "\n",
    "* How could you imagine context playing a role here?\n",
    "* What are some other literary applications for POS tagging questions?\n",
    "* For supervised learning problems?\n",
    "* What other kinds of research questions are available here?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
